--- 
title: "" 
author: "Adam Braffman and Yuchen Luo" 
date: "`r format(Sys.time(), '%d %B, %Y')`" 
output:
  pdf_document: default
---

```{r setup, include=FALSE}
library(igraph)
library(tidyverse)
library(readr)
library(ggplot2)
library(data.table)
library(gtsummary)
library(kableExtra)
```



```{r set up data, echo= FALSE}  

df = read.csv('RDD_dat_eigen.csv')

df$post = ifelse(df$year<2010, 0, 1)
df$trans_yr = as.numeric(df$year)-2010

# 
# 
# ggplot(data = df,aes(x = as.numeric(year), y = EV, color = as.factor(post))) +
#   geom_smooth(method = 'lm', formula = y~x)

```
# Motivation

Since their introduction to U.S. politics in the 1940s, Political action committees (PACs)---tax-exempt organizations that funnel campaign contributions to campaigns, referenda, or legislation---have had a \$2,500 cap on individual contributions, which could come from, e.g., individuals, corporations, or unions. In the landmark decision of January 2010, *Citizens United v. Federal Election Commission*, the U.S. Supreme Court argued that becausee financial donations are essential to free speech, setting limits on campaign contributions violates the First Amendment. The decision removed the $2,500 donor limit and effectively introduced into the networks of the American party system an organizational entity---the Super PAC---that can amass unlimited dollar amounts in order to influence political decision-making. What has been the effect of the 2010 *Citizens United* decision and Super PACs on the evolution political donor networks? 

A growing social science literature views the American party system as coalition networks consisting of governmental and nongovernmental organizations. In these studies, sometimes referred to as the Extended Party Network (EPN) approach, authors use social network analysis to reveal the often covert relationships that exist between campaigns and donors. Such analyses of extended political party networks, however, tend to be exploratory and descriptive, aimed at the identification of positions in whole structures and exchange processes. In this study, we use two causal inference methods, regression discontinuity (RDD) and difference-in-difference (DiD) design, to measure the effects of the 2010 *Citizens United* decision on the influence of PACs within state donor networks.  

# Data. 

We use candidate donation data from the National Institute on Money in Politics (NIMP). For each election, the data include the total amount donated from an organization to a candidate. NIMP researchers standardize donor names and code economic interest/industry based on occupation information contained in disclosure reports. 

From these data, @reuning2020mapping generated a network that consists of state party networks for 47 states from 2000 to 2016. The edge lists contain donor node IDs and their edge weights for all House and Senate elections. Edge weights identify edges at different thresholds of connectedness. Shared donations between groups constitute an edge, and edges are weighted both by how many donations they share and how much they donate [@reuning2020mapping, 274]. The weights take values of one through five---the higher the value, the more tightly connected are the two donor groups. 

House members serve two-year terms, with elections taking place every even year, and senators serve six-year terms with about only one-third up for reelection in any election. Because we are interested in the effects of the 2010 *Citizens United* decision on campaign donation networks, we restricted the data to donor networks for House campaigns. Merging the edge lists of the House donor networks yields a total of 172, 368 observations for years 2001-2015. 


# Estimands

In this project, what we are interested in is the average treatment effect (ATE) of the 2010 SCOTUS decision on political donors' influence in their network. This can be shown in formula 

$E[Y(1)-Y(0)]$ 

We choose this as our estimand because it is the estimand best fit for our project. Although the 2010 SCOTUS decision will likely only impact certain donors who have the willingness and ability to donate more than the previously stipulated $2500 amount, those high-donors changing patterns of donation will impact the position and attributes of the entire donation network. Therefore it does not make a lot of sense to only look at the average treatment for only treatment or only control group. 

# Methods
## Method One: Regression Discontinuity 

   The first method we use to estimate our estimand is called regression discontinuity. Regression discontinuity a special case of an observational study design in which whether a unit receives treatment is decided solely based on values of one variable, usually referred to as the running variable. In this setting, there is a cutoff point on the running variable, where on one side all units receive the threatment and units on the other side do not. In a regression discontinuity model, it is usually assumed that the only confounding covariate is the running variable, given the appropriate bandwith around the cutoff point. Around the cutoff point, usually the units are considered randomly distributed so other confounding factors can be ignored. This method is appropriate for situations where researchers don't have access to a lot of confounding covariate data.
   
   In our project, the running variable is time, measured in year. And the cutoff point is at year 2010 when the Supreme Court Decision was made. We have set our bandwidth to be from 2009-2011. The reason for choosing our bandwidth is that 1) first, this is the smallest bandwidth that our dataset allows, and with this small bandwidth we have more confidence that donors in this time frame are more likely to be similarly/randomly distributed. 2) Second, since the running variable in our dataset is relatively "coarse", meaning that year is really a large span of time. If we extend our bandwidth wider, then it would be unreasonable to assume the distribution of donors are still random across more than two years, with changing economical and political landscape. 
   
   We decide to use a linear model based on a preliminary plot, and based on the lowess curve (see figure below) the relationship between time and eigenvector centrality of campaign donors are linear than quadratic. So here in our regression discontinuity model we assume that their relationship is linear, except at the cutoff point. 

```{r datashape}
ggplot(data = df %>% sample_frac(0.1),aes(x = as.numeric(year), y = EV, color = as.factor(post))) +
  geom_jitter() +
  geom_smooth(method = 'loess', color = "blue")
```
   In practice, we first restrict the model to the bandwidth, only considering the data points from years 2009 to 2011. We then create a variable to indicate the applicability of the Supreme Court decision, if before 2010 then 0 and otherwise 1. We fit the restristed dataset (from 2009 -2011) to a linear model, where the applicability indicator and year was used to predict the eigenvector centrality. 
   
   To answer our second question about potential partisan difference in the treatment effect, we divide our dataset to two parts for the regression discontinuity analysis. The first part is focused on the traditionally/previously Republican donors, defined as those whose mean proportion of donation pre-2010 for Republican Congress members is larger than 60%. The second part is focused on the traditionally/previously
   Democratic donors, defined as those whose mean proportion of donation pre-2010 for Democratic Congress members is larger than 60%. Focusing on the proportion of partisan donation pre-2010 helps us avoid controlling on post-treatment variables. With those two data sets we repeat the same process for regression discontinuity modeling as we did for the overall dataset. 
   
## Method Two: Difference in Difference

  Difference in Difference method is an observational method that mimics an experimental design, by taking the differential effect of a treatment on a treatment group and a control group. The way that DID estimates the treatment is by comparing the outcome change over time of both treatment and control groups. This method assumes that both treatment and control group's outcome change similarly over time. Therefore, by taking the difference between treatment group outcome and control group temporal outcome change, this method can get can mitigate effects of extraneous factors.
  
  In our project, we choose donors in the state of Vermont as our control group. Shortly after the SCOTUS decision, the U.S. District Court for the District of Vermont ruled in Vermont Right to Life Committee v. Sorrell (II) that Vermont's contribution limits did apply to independent expenditure PACs, making Vermont somewhat free from the influence of the 2010 SCOTUS ruling. 
  
  Similar to our RDD model, here we also assume that the basic form of our model is linear, based on a preliminary observation our our data relationship.
  
  In practice, we use all available years of our data. Similar to the RDD model, we also create a binary variable to indicate the applicability of the Supreme Court decision, if before 2010 then 0 and otherwise 1. We then create another binary variable to indicate whether a data point is in the treatment group or control group - if the donation happens in Vermont, then it is in control group, if not then it is in treatment group. Finally, we run an interation model, that uses treatment indicator, applicability indicator and their interaction term as predictor and the eigenvector centrality as outcome. The coefficient of the interaction term is the estimate we are looking for. 
  
  To answer our second question about potential partisan difference in the treatment effect, we fit a different model adding in variable to indicate the partisanship of the donor, defined in the same way as we did in the regression discontinuity model. We then run a similar difference in difference model, keeping all other predictors the same while only adding this partisan variable. We also run an anova test to see if adding the partisanship variable contributes to our model. 

# Assumptions. Define the assumptions required for each method to identify a causal
effect and discuss their plausibility in the given setting. Several paragraphs.

## Method One: Regression Discontinuity

### First assumption: Randomization
The first assumption about regression discontinuity is that the treatment assignment is ignorable given X in a narrow interval of X around the cutoff. This means that we assume that data points are randomly distributed around the cutoff point, therefore other confounding factors can be ignored.

In our case, the randomization assumption is plausible because we set our bandwidth narrow enough (as narrow as possible). From 2009-2011, in the political campaign donation nothing major happened except our treatment variable. It is reasonable to assume that the bigger economic and political conditions are relatively stable.

### Second Assumption: Parametric form

The second assumption we are making here is that data on both sides of the cutoff follow a linear relationship with the running variable. This assumption is much tougher to say, since from the scatter plot we can see that the distribution of the data points are rather regular, and it seems like they don't follow a clear parametric relationship. However, since our bandwidth is small, it is also more likely that the parametric assumption holds. 

### Third Assumption: Bandwidth
The third assumption we made here is going with the small bandwidth we chose. We think that choosing this bandwidth makes sense because a smaller bandwidth helps our first and second assumption more plausible. Even though the generalizability of our finding might suffer a bit, from a theoretical persepctive, it is important we don't over generalize. For example, if we go back to 2007 or 2008, we suffer from possible strong bias from confounding factors such as the 2008 Great Recession, or a different political administration in 2007. 

## Method Two: Difference in Difference 
To identify Average Treatment Effect (ATE), we need the difference of both treatment and control group to be independent of treatment assignment, and that we need to have the treatment group to look like the control group. Colloquially, this is also known as the parallel trend assumption.

In our case, this assumption is a bit questionable. Because we use only Vermont as our control group, it really isn't that reliable. Being the home state of Bernie Sanders, Vermont has a very disctinct political culture and legal system that fosters its lack of SuperPac forming, which is very different from many other states in the treatment group. Other indicators such as economic development and party identification also makes Vermont not an equal counterpart to our treatment group states. It is likely that the D(1) of Vermont is different from those in the treatment group, and the D(0) of the treated is different from that of Vermont's. But with the data we have, and how the 2010 SCOTUS decision is so sweeping across states, Vermont is our best bet. 


# Diagnostics. Present and discuss diagnostics appropriate to each method (e.g. balance
tables or plots for propensity score analyses, regression diagnostics for methods that
rely on linear models). Several paragraphs of text in addition to appropriate
tables/plots. [Note that if you use two different propensity score methods you need to
present separate diagnostics for each!]

```{r diag, echo = F}

# mean percent of dem donation pre 2010
mean_party = df %>% group_by(donor) %>% filter (year <2010) %>% summarise(mean(PerDem))
colnames(mean_party)[2] = "avg_PerDem"
df = left_join(df, mean_party, by = 'donor')
df$party = ifelse(df$avg_PerDem >0.6, "Dem", ifelse(df$avg_PerDem < 0.4, "Rep", "None"))


# restrict df to 2009 - 2011
df_res = df[df$year<2012 & df$year >2008, ]

total = lm(EV ~ trans_yr+post, data = df_res)

### test partisanship
setDT(df_res)
df_rep = df_res[party == 'Rep',]
df_dem = df_res[party == 'Dem',]

lin_rep = lm(EV ~ trans_yr+post, data = df_rep)
lin_dem = lm(EV ~ trans_yr+post, data = df_dem)

# DID estimate of E[Y(1)-Y(0) | Z=0]

df$treated = ifelse(df$state == "VT", 0, 1)

didreg1 = lm(EV~ treated*post + trans_yr, data = df)

didreg2 = lm(EV~ treated*post + trans_yr + party, data = df)

#anova(didreg1, didreg2)

# vanilla regression

vanilla = lm(EV~ post + trans_yr, data = df)

# present graphs
par(mfrow = c(2, 2))
plot(total)


plot(lin_dem)
title(main = "RDD for Dems")

plot(lin_rep)

plot(didreg1)

plot(didreg2)


```
In our project we ran a total of four linear regression models. The first one is regression discontinuity model, restricted from 2009 to 2011. The second and the third models are the stratified version of the first one, on democratic donors and republican donors respectively. The fourth and fifth are difference in difference models, with the former not including extra covariates and the latter including partisanship indicator as a covariate. 

The results of the regression diagnostics are shown as above. For model one (basic RDD), we can see from the Residuals vs. Fitted graph that the linear parametric assumption seems right. The QQ plot shows that data at both ends do not have normally distributed, but most of the data points are. The the line in the Scale-Location figure is relatively straight, so it is relatively safe to say in our regression homoscedasticity holds relatively well. In the Residuals vs Leverage figure, we see some points have really high leverage and high influence, but none has extreme residuals (none with standard residual larger than 3).

For model 2 (RDD for previously democratic donors), the diagnostics are very similar to model one. We can see from the Residuals vs. Fitted graph that the linear parametric assumption seems right. The QQ plot shows that data at both ends do not have normally distributed, but most of the data points are. The the line in the Scale-Location figure is relatively straight too homoscedasticity holds relatively. In the Residuals vs Leverage figure, we see some points have really high leverage and high influence, but none has extreme residuals. For model 3 (RDD for previously democratic donors), things are bit different. Linear assumption still holds, but the residuals do not really follow a normal distribution. Homoscedasticity still holds and there seem to be many fewer high leverage and high influence points. 

For model 4 (basic DID), linear assumption holds. Data at both ends do not have normally distributed, but most of the data points are. Homoscedasticity still holds and there seem to be many fewer high leverage and high influence points, compared to basic RDD model. For model 5 (DID with previous party indicator as covariate), the story is very similar to model 4 except for homoscedasticity. From the Scale-Location graph, it seems that residuals are increasing with fitted values. So it is very likely this model is heteroscedasticitic. 

# Results. 

  As can be seen from the regression table, the estimates of ATE are all coefficient of the binary indicator of pre/post 2010 variable, except for the DID model, in which the iteraction term between the treatment variable and the pre/post-2010 indicator is the estimator. 

```{r RDD, echo= FALSE, message = FALSE}


library(stargazer)

stargazer(total, lin_rep, lin_dem, didreg1, didreg2, vanilla,
          column.labels = c("RDD", "RDD.Rep", "RDD.Dem", 
                            "DID", "DID.party","LinRegression"),
          title="Regression Results",
          type = "text",
          omit.stat=c("LL","ser","f"), 
          column.sep.width = "-15pt", font.size = "tiny")



```




The estimates for the regression discontinuity model are all statistically significant. To provide a proper causal inpterpretation of this, our analysis shows that on average, the 2010 SCOTUS decision caused a 0.036 increase in donors' influence in the donation networks, measured in eigenvector centrality. Looking at partisanship divide, in our regression discontinuity methods, interesting pattern emgerges as on average the 2010 SCOTUS decision decreased Republican donors' influence by 0.074 and increased Democratic donors' influence by 0.068. We can be more certain about the negative impact on Democratic donors, since in our data there are many more Democratic donors than Republican ones. 

In our difference in difference method, both the basic model and the model that contains the party variable return insignificant estimates of the effect. Despite the fact that we have a lot of observations, we cannot get a signigicant estimate of the DID treatment effect. This makes sense as we laid out earlier in the assumptions section, that Vermont is probably a poor control group and there is probably a lot of confounding biases. To provide a proper causal inpterpretation of this despite the result being insignificant, our analysis shows that on average, the 2010 SCOTUS decision caused a 0.013 decrease in donors' influence in the donation networks, measured in eigenvector centrality. When taking into consideration of partisanship, the 2010 SCOTUS decision caused a 0.029 increase in donors' influence in the donation networks, measured in eigenvector centrality; and Republican donors had 0.137 decrease in influence as a result of the treatment, compared with Democratic donors.

The effectiveness of the RDD model can be seen in comparison with the final vanilla linear regression model. The final model still shows a positive effect of the treatment, yet the estimate is much smaller. It makes sense because RDD narrows in on the period of treatment and can get a better grasp of the effect of treatment, instead of looking at all data globally. 



# Discussion
Our analysis confirms our chief hypothesis with the regression discontinuity model. The analysis shows that the 2010 SCOTUS decision to remove the upper limit of PAC donations on average caused the campaign donors to have 0.036 higher eigenvector centrality, commonly used to denote a node's influence in a network. Although the numeric value is small, the fact that eigenvector centrality is a value between 0 and 1 indicates that the effect is quite drastic. 

The biggest problem we had in our analysis is with our difference in difference design. In our DiD model, the estimate is not significant. We think this is due to the fact that Vermont is a poor control for the rest of the country. Future research looking to use DiD design on this problem should consider locating data about each donor's information and use propensity score methods to match donors across treatment and control states to achieve better comparability. 

This study is limited in its unit of analysis and choice of bandwidth. The nature of the data determines that we can only slice our running variable discretely by year, since House elections occur biannually. Our running variable, then, is fairly imprecise, and in many cases our data look very discrete. This limits our ability to experiment with more types of bandwidth without violating ignorability and parametric assumptions.

Future research should take into account these limitations. In particular, researchers should construct a more fine-grained temporal variable. For example, FEC data include receipt dates for campaign donations. These receipt dates might be used to construct a more precise bandwidth around the discontinuity of the SCOTUS Citizens United decision. Furthermore, researchers could these FEC data to get around the problem of adequate controls by, as noted above, matching donors across groups. 

Viewing parties as networks allows us to make considerable progress on research problems concerning the power and influence that campaign finance holds over political agenda-setting and decision-making. Our results provide some preliminary support for the notion that the Citizens United decision, which commentators often assume has had the effect of increasing the power of wealthy donors, has had the effect of increasing levels of political influence for such donors. Because research backs up the association between higher incomes and Republican votes, the related assumption is that the Citizens United decision has had an outsize benefit for Republican Party donors. However, our results show the opposite. Since 2010, Democratic party donors increased in network influence, whereas Republican party donors decreased in influence. Despite the limitations of the study, these results are worth the attention of both network methodologists who want to improve on the ability to make causal inferences from network data and subject experts who want to understand the relational impact of landmark SCOTUS decisions on the structure of political parties and their financial ties.




